#!/usr/bin/env python3
"""
Unit tests for vulnerability-mgmt scanners and SBOM
"""

import json
import sys
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock

import pytest

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))


class TestVulnerabilityScanner:
    """Test vulnerability scanning functionality"""

    def test_vulnerability_structure(self, sample_vulnerability):
        """Test vulnerability data structure"""
        assert 'id' in sample_vulnerability
        assert 'severity' in sample_vulnerability
        assert 'cvss_score' in sample_vulnerability
        assert 'title' in sample_vulnerability

        # Validate CVE ID format
        assert sample_vulnerability['id'].startswith('CVE-')

    def test_vulnerability_severity_levels(self, severity_level):
        """Test vulnerability severity classification"""
        assert severity_level in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'INFO']

    def test_cvss_score_range(self, sample_vulnerability):
        """Test CVSS score is in valid range"""
        cvss = sample_vulnerability['cvss_score']
        assert 0.0 <= cvss <= 10.0

    def test_scan_result_structure(self, sample_vulnerability_scan_result):
        """Test scan result structure"""
        assert 'scan_id' in sample_vulnerability_scan_result
        assert 'timestamp' in sample_vulnerability_scan_result
        assert 'target' in sample_vulnerability_scan_result
        assert 'vulnerabilities' in sample_vulnerability_scan_result
        assert 'summary' in sample_vulnerability_scan_result

    def test_scan_summary_counts(self, sample_vulnerability_scan_result):
        """Test scan summary count accuracy"""
        summary = sample_vulnerability_scan_result['summary']
        vulns = sample_vulnerability_scan_result['vulnerabilities']

        assert summary['total'] == len(vulns)

        # Count by severity
        high_count = sum(1 for v in vulns if v['severity'] == 'HIGH')
        medium_count = sum(1 for v in vulns if v['severity'] == 'MEDIUM')

        assert summary['high'] == high_count
        assert summary['medium'] == medium_count


class TestSBOMGeneration:
    """Test SBOM (Software Bill of Materials) functionality"""

    def test_sbom_structure(self, sample_sbom):
        """Test SBOM data structure"""
        assert 'bomFormat' in sample_sbom
        assert 'specVersion' in sample_sbom
        assert 'components' in sample_sbom
        assert 'metadata' in sample_sbom

    def test_sbom_format_cyclonedx(self, sample_sbom):
        """Test CycloneDX SBOM format"""
        assert sample_sbom['bomFormat'] == 'CycloneDX'
        assert sample_sbom['specVersion'] in ['1.4', '1.5', '1.6']

    def test_sbom_components(self, sample_sbom):
        """Test SBOM component structure"""
        components = sample_sbom['components']

        assert len(components) > 0

        for component in components:
            assert 'type' in component
            assert 'name' in component
            assert 'version' in component

    def test_sbom_purl_format(self, sample_sbom):
        """Test PURL (Package URL) format"""
        components = sample_sbom['components']

        for component in components:
            if 'purl' in component:
                purl = component['purl']
                # PURL should start with pkg:
                assert purl.startswith('pkg:')


class TestRiskScoring:
    """Test vulnerability risk scoring"""

    def test_risk_score_calculation(self):
        """Test risk score calculation algorithm"""
        # Risk factors
        cvss_score = 7.5
        exploitability = 0.8  # High exploitability
        asset_criticality = 0.9  # Critical asset
        environment_factor = 0.7  # Production environment

        # Simple risk calculation: weighted average
        risk_score = (
            cvss_score * 0.4 +
            exploitability * 10 * 0.3 +
            asset_criticality * 10 * 0.2 +
            environment_factor * 10 * 0.1
        )

        assert 0 <= risk_score <= 10
        assert isinstance(risk_score, float)

    def test_prioritization_scoring(self):
        """Test vulnerability prioritization"""
        vulnerabilities = [
            {'id': 'CVE-1', 'cvss': 9.0, 'exploited_wild': True},
            {'id': 'CVE-2', 'cvss': 5.0, 'exploited_wild': False},
            {'id': 'CVE-3', 'cvss': 7.5, 'exploited_wild': True}
        ]

        # Sort by CVSS and exploitation status
        def priority_score(vuln):
            base = vuln['cvss']
            if vuln['exploited_wild']:
                base += 2  # Boost for active exploitation
            return base

        sorted_vulns = sorted(vulnerabilities, key=priority_score, reverse=True)

        # CVE-1 should be highest priority (9.0 + 2 = 11)
        assert sorted_vulns[0]['id'] == 'CVE-1'


class TestScannerIntegrations:
    """Test scanner integrations"""

    @patch('subprocess.run')
    def test_nmap_scanner_execution(self, mock_run):
        """Test Nmap scanner execution"""
        mock_run.return_value = Mock(
            returncode=0,
            stdout='Nmap scan completed',
            stderr=''
        )

        # Simulate nmap scan
        result = mock_run(['nmap', '-sV', '192.168.1.1'])

        assert result.returncode == 0
        mock_run.assert_called_once()

    @patch('subprocess.run')
    def test_trivy_scanner_execution(self, mock_run):
        """Test Trivy container scanner"""
        mock_run.return_value = Mock(
            returncode=0,
            stdout='{"Results": []}',
            stderr=''
        )

        # Simulate trivy scan
        result = mock_run(['trivy', 'image', 'nginx:latest'])

        assert result.returncode == 0

    def test_openvas_result_parsing(self):
        """Test OpenVAS result parsing"""
        openvas_result = {
            "results": [
                {
                    "nvt": {
                        "oid": "1.3.6.1.4.1.25623.1.0.12345",
                        "name": "Test Vulnerability"
                    },
                    "severity": 7.5,
                    "host": "192.168.1.10",
                    "port": "443/tcp"
                }
            ]
        }

        assert 'results' in openvas_result
        assert len(openvas_result['results']) > 0


class TestThreatIntelligence:
    """Test threat intelligence integration"""

    def test_kev_catalog_check(self):
        """Test KEV (Known Exploited Vulnerabilities) catalog"""
        kev_entry = {
            "cveID": "CVE-2025-12345",
            "vendorProject": "Test Vendor",
            "product": "Test Product",
            "dateAdded": "2025-10-15",
            "knownRansomwareCampaignUse": "Known"
        }

        assert 'cveID' in kev_entry
        assert 'dateAdded' in kev_entry
        assert kev_entry['knownRansomwareCampaignUse'] in ['Known', 'Unknown']

    def test_nvd_api_response(self):
        """Test NVD API response structure"""
        nvd_response = {
            "resultsPerPage": 1,
            "totalResults": 1,
            "vulnerabilities": [
                {
                    "cve": {
                        "id": "CVE-2025-12345",
                        "sourceIdentifier": "nvd@nist.gov",
                        "published": "2025-10-15T00:00:00.000",
                        "metrics": {
                            "cvssMetricV31": [{
                                "cvssData": {
                                    "baseScore": 7.5
                                }
                            }]
                        }
                    }
                }
            ]
        }

        assert 'vulnerabilities' in nvd_response
        assert 'totalResults' in nvd_response


class TestReportGeneration:
    """Test vulnerability report generation"""

    def test_html_report_generation(self, tmp_path, sample_vulnerability_scan_result):
        """Test HTML report generation"""
        report_file = tmp_path / "vuln_report.html"

        # Simulate report generation
        html_content = f"""
        <html>
        <head><title>Vulnerability Report</title></head>
        <body>
            <h1>Scan Results</h1>
            <p>Total Vulnerabilities: {sample_vulnerability_scan_result['summary']['total']}</p>
        </body>
        </html>
        """

        report_file.write_text(html_content)

        assert report_file.exists()
        assert "Vulnerability Report" in report_file.read_text()

    def test_json_report_generation(self, tmp_path, sample_vulnerability_scan_result):
        """Test JSON report generation"""
        report_file = tmp_path / "vuln_report.json"

        with open(report_file, 'w') as f:
            json.dump(sample_vulnerability_scan_result, f, indent=2)

        assert report_file.exists()

        with open(report_file, 'r') as f:
            data = json.load(f)

        assert 'vulnerabilities' in data

    def test_markdown_report_generation(self, tmp_path, sample_vulnerability_scan_result):
        """Test Markdown report generation"""
        report_file = tmp_path / "vuln_report.md"

        md_content = f"""
# Vulnerability Scan Report

**Scan ID:** {sample_vulnerability_scan_result['scan_id']}
**Target:** {sample_vulnerability_scan_result['target']}

## Summary
- Total: {sample_vulnerability_scan_result['summary']['total']}
- High: {sample_vulnerability_scan_result['summary']['high']}
- Medium: {sample_vulnerability_scan_result['summary']['medium']}
"""

        report_file.write_text(md_content)

        assert report_file.exists()
        assert "Vulnerability Scan Report" in report_file.read_text()


# [+] Integration Tests
@pytest.mark.integration
class TestVulnerabilityManagementWorkflow:
    """Test complete vulnerability management workflow"""

    def test_scan_to_report_workflow(self, tmp_path):
        """Test complete scan-to-report workflow"""
        # 1. Scan execution (mocked)
        scan_result = {
            "scan_id": "test-001",
            "vulnerabilities": [],
            "summary": {"total": 0}
        }

        # 2. SBOM generation
        sbom = {
            "bomFormat": "CycloneDX",
            "components": []
        }

        # 3. Risk scoring
        # (would calculate risks here)

        # 4. Report generation
        report_file = tmp_path / "report.json"
        with open(report_file, 'w') as f:
            json.dump({"scan": scan_result, "sbom": sbom}, f)

        assert report_file.exists()


# [+] Parametrized Tests
@pytest.mark.parametrize("scanner", ["nmap", "openvas", "trivy", "nuclei"])
def test_scanner_support(scanner):
    """Test different scanner types"""
    assert scanner in ["nmap", "openvas", "trivy", "nuclei", "nikto"]


@pytest.mark.parametrize("severity", ["CRITICAL", "HIGH", "MEDIUM", "LOW", "INFO"])
def test_severity_classification(severity):
    """Test severity levels"""
    severity_order = ["INFO", "LOW", "MEDIUM", "HIGH", "CRITICAL"]
    assert severity in severity_order


@pytest.mark.parametrize("cvss_version", ["v2", "v3.0", "v3.1", "v4.0"])
def test_cvss_versions(cvss_version):
    """Test CVSS version support"""
    assert cvss_version in ["v2", "v3.0", "v3.1", "v4.0"]


# [+] Slow/Integration Tests
@pytest.mark.slow
@pytest.mark.requires_network
def test_nvd_api_connectivity():
    """Test connectivity to NVD API"""
    # This would actually test API connectivity
    # Skipped in offline environments
    pass
